{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inception_zoomclf.ipynb","provenance":[{"file_id":"1ffM7lUElly506zGPRTy0gIxNTDe_4Y9v","timestamp":1591697961710},{"file_id":"1tcdmtxIC0itkAoXnGBLIkmlVX_iB895a","timestamp":1591625675633},{"file_id":"12-mOSUZuEsgeAkOFAWXM_IiHrxITLhks","timestamp":1589735473582}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1rmI2rnr5e48","colab_type":"text"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"H586gtoqJ0cu","colab_type":"text"},"source":["## Imports "]},{"cell_type":"code","metadata":{"id":"4Hu65BTA5ikD","colab_type":"code","colab":{}},"source":["from PIL import Image\n","from sklearn import utils\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.model_selection import train_test_split\n","from torch.autograd import Function\n","from torch.backends import cudnn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Subset, DataLoader\n","from torch.utils.model_zoo import load_url as load_state_dict_from_url\n","from torchvision import models\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torchvision.datasets import VisionDataset\n","from torchvision.models import alexnet\n","from torchvision.transforms.functional import pad\n","from tqdm import tqdm\n","import logging\n","import matplotlib.pyplot as plt\n","import numbers\n","import numpy as np\n","import os\n","import os.path\n","import shutil\n","import sys\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import zipfile\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cj5JB6kEERnD","colab_type":"text"},"source":["## Drive mount\n"]},{"cell_type":"code","metadata":{"id":"t2lEIpWVENIO","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NFU0zaIg5kXL","colab_type":"text"},"source":["## File extraction and setup"]},{"cell_type":"code","metadata":{"id":"6qkGdgL53yJY","colab_type":"code","colab":{}},"source":["if not os.path.exists(\"/content/ROD.zip\"):\n","  !cp -r \"/content/drive/My Drive/DL_project/ROD.zip\" \"/content/\"\n","if not os.path.exists(\"/content/synROD.zip\"):\n","  !cp -r \"/content/drive/My Drive/DL_project/synROD.zip\" \"/content/\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckCwdxUWchGj","colab_type":"text"},"source":["## Path variables declaration and download"]},{"cell_type":"code","metadata":{"id":"6jiX_YDmBDiw","colab_type":"code","colab":{}},"source":["rod_path = \"/content/ROD/ROD\"\n","synrod_path = \"/content/synROD/synROD\"\n","rod_destination_path = \"/content/ROD\"\n","synrod_destination_path = \"/content/synROD\"\n","\n","if not os.path.isdir(rod_destination_path) and not os.path.exists(\"/content/ROD.zip\"):\n","  # ROD \n","  # https://drive.google.com/open?id=1p1GORdB44NjtNWJ4d1xqttseM1X9lWNF\n","  # https://drive.google.com/open?id=168neCvaHwMffFOqjOkth-wVaP4tRFuSW\n","  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=168neCvaHwMffFOqjOkth-wVaP4tRFuSW\" > /dev/null\n","  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=168neCvaHwMffFOqjOkth-wVaP4tRFuSW\" -o \"ROD.zip\"\n","\n","if not os.path.isdir(synrod_destination_path) and  not os.path.exists(\"/content/synROD.zip\"):\n","  # synROD \n","  # https://drive.google.com/open?id=1rry4GViJLmmMpbm0B2s7MyQs5Dx8pFS3\n","  # https://drive.google.com/open?id=1V1fthSNAvsPRF6hLt_kf_xonw7lxAV03\n","  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1V1fthSNAvsPRF6hLt_kf_xonw7lxAV03\" > /dev/null\n","  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1V1fthSNAvsPRF6hLt_kf_xonw7lxAV03\" -o \"synROD.zip\"\n","# Extract ROD dataset\n","if not os.path.isdir(rod_destination_path):\n","  with zipfile.ZipFile(\"/content/ROD.zip\", 'r') as zip_ref:\n","      zip_ref.extractall(rod_destination_path)\n","\n","# Extract synROD dataset\n","if not os.path.isdir(synrod_destination_path):\n","  with zipfile.ZipFile(\"/content/synROD.zip\", 'r') as zip_ref:\n","      zip_ref.extractall(synrod_destination_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3x7Uhfot5hDs","colab_type":"code","colab":{}},"source":["\"\"\"\n","# Extract ROD dataset\n","rod_path = \"/content/ROD/ROD\"\n","synrod_path = \"/content/synROD/synROD\"\n","\n","rod_destination_path = \"/content/ROD\"\n","if not os.path.isdir(rod_destination_path):\n","  with zipfile.ZipFile(\"/content/ROD.zip\", 'r') as zip_ref:\n","      zip_ref.extractall(rod_destination_path)\n","\n","# Extract synROD dataset\n","synrod_destination_path = \"/content/synROD\"\n","if not os.path.isdir(synrod_destination_path):\n","  with zipfile.ZipFile(\"/content/synROD.zip\", 'r') as zip_ref:\n","      zip_ref.extractall(synrod_destination_path)\n","\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRk1caT8K31v","colab_type":"text"},"source":["## Copy in current folder datasets and net classes"]},{"cell_type":"code","metadata":{"id":"4B__Yny4K9o3","colab_type":"code","colab":{}},"source":["!cp -r \"/content/drive/My Drive/inception_models/dataset/.\" \"/content/\"\n","!cp -r \"/content/drive/My Drive/inception_models/net/.\" \"/content/\"\n","!cp -r \"/content/drive/My Drive/inception_models/transform_config/.\" \"/content/\"\n","!cp -r \"/content/drive/My Drive/inception_models/splits/.\" \"/content/\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sp9oWROBKxqm","colab_type":"text"},"source":["## Import datasets, net and configurator classes"]},{"cell_type":"code","metadata":{"id":"IEaktSSiK2L2","colab_type":"code","colab":{}},"source":["from synrod import SynRODMOD\n","from rod import RODMOD\n","from rod_utils import *\n","from dcepnet_concat_kaiming import DCepNet\n","from tconfig import TransformConfig"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XTSnQWEdKW-K","colab_type":"text"},"source":["# Train test zoomclf function definition"]},{"cell_type":"code","metadata":{"id":"HI0VOKnfKbkb","colab_type":"code","colab":{}},"source":["def train_test_variation(synrod_train, synrod_validation, rod, hyperparams, light_validation=False):\n","  \"\"\"Train our variation to the paper architecture with zoom pretext task.\n","  The net is trained in end-to-end fashion.\n","\n","  Args:\n","    synrod: train dataset\n","    rod: test dataset\n","    hyperparams: parameters dict with the keys\n","      {\n","        lr\n","        batch_size\n","        weight_decay \n","        step_size\n","        epochs \n","        lambda (!!!)\n","        momentum (optional, default 0.9)\n","        gamma (optional, default 0.1)\n","      }\n","    light_validation: if True the validation is done only in the last epoch.\n","\n","  Return: \n","    (trained_model, train_loss, train_acc, test_loss, test_acc).\n","  \"\"\"\n","  lr = hyperparams[\"lr\"]\n","  batch_size = hyperparams[\"batch_size\"]\n","  weight_decay = hyperparams[\"weight_decay\"]\n","  step_size = hyperparams[\"step_size\"]\n","  epochs = hyperparams[\"epochs\"]\n","  curr_momentum = hyperparams.get(\"momentum\", 0.9)\n","  curr_gamma = hyperparams.get(\"gamma\", 0.1) \n","  lambda_ = hyperparams[\"lambda\"]\n","\n","  decay_policy = hyperparams[\"lr_epoch_num_decay_policy\"]\n","  use_fixed_stepsize = decay_policy == None\n","\n","  em_weight = 0.1\n","  DEVICE = \"cuda\"\n","  cudnn.benchmark\n","\n","  # dataloader definition with given batch size\n","  N_WORKERS = 4\n","  source = DataLoader(synrod_train,  batch_size=batch_size, shuffle=True, drop_last=True, num_workers=N_WORKERS, collate_fn=collate)\n","  source_validation = DataLoader(synrod_validation,  batch_size=batch_size, shuffle=True, drop_last=True, num_workers=N_WORKERS, collate_fn=collate)\n","  source_rot = DataLoader(synrod_train,  batch_size=batch_size, shuffle=True, drop_last=True, num_workers=N_WORKERS, collate_fn=collate)\n","  target_rot = DataLoader(rod,  batch_size=batch_size, shuffle=True, drop_last=True, num_workers=N_WORKERS, collate_fn=collate)\n","  target = DataLoader(rod,  batch_size=batch_size, shuffle=True, drop_last=True, num_workers=N_WORKERS, collate_fn=collate)\n","\n","  # NET DEFINITION\n","  net = DCepNet(num_classes=47, pretext_classes=5).to(\"cuda\")\n","\n","  criterion = nn.CrossEntropyLoss()\n","  main_criterion = nn.CrossEntropyLoss() \n","  \n","  pretext_criterion = nn.CrossEntropyLoss()\n","  entropy_min_criterion = HLoss()\n","\n","  parameters_to_optimize = net.parameters() \n","  optimizer = optim.SGD(parameters_to_optimize, lr=lr, \n","                            momentum=curr_momentum, \n","                            weight_decay=weight_decay)\n","  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=curr_gamma)\n","\n","  # lists that accumulate loss/accuracy values over the training period\n","  train_loss = []\n","  train_acc = []\n","  validation_acc = []\n","  validation_loss = []\n","  test_loss = []\n","  test_acc = []\n","\n","  # update is set to perfect squares epoch number\n","  next_update_epoch = 1\n","  slow_schedule_count = 1\n","  iter_count = 1\n","\n","  running_corrects = 0\n","  tot_samples = 0\n","  for i in range(epochs):\n","    counter_mod = 0\n","    n_iters = 0\n","    train_main_acc_val = 0\n","    train_main_loss_val = 0\n","\n","    train_zoom_source_acc_val = 0\n","    train_zoom_source_loss_val = 0\n","\n","    train_zoom_target_acc_val = 0\n","    train_zoom_target_loss_val = 0\n","    \n","    test_main_acc_val = 0\n","    test_main_loss_val = 0\n","    batch_count = 0\n","    net.train()\n","    for source_batch, target_batch, source_rot_batch, target_rot_batch in zip(source, target, source_rot, target_rot):\n","      net.train()\n","      S, _ = format_batch(source_batch, pretext_task=\"zoomclf\")\n","      T, _ = format_batch(target_batch, pretext_task=\"zoomclf\")\n","\n","      _, S_hat = format_batch(source_rot_batch, pretext_task=\"zoomclf\")\n","      _, T_hat = format_batch(target_rot_batch, pretext_task=\"zoomclf\")\n","\n","      # zero the gradients\n","      optimizer.zero_grad() \n","\n","      # MAIN TASK\n","      # setup SOURCE DOMAIN STANDARD dataset to feed to the net\n","      source_rgb_images = S[\"rgb\"].to(DEVICE)\n","      source_depth_images = S[\"depth\"].to(DEVICE)\n","      source_main_labels = S[\"label\"].to(DEVICE)\n","      # train on source original images \n","      outputs, out_aux  = net.forward(source_rgb_images, source_depth_images, mode=\"main\")\n","      loss_M = criterion(outputs, source_main_labels)\n","      loss_aux = criterion(out_aux, source_main_labels)\n","      # compute stats\n","      _, preds = torch.max(outputs.data, 1)\n","      running_corrects = torch.sum(preds == source_main_labels.data).data.item()\n","      tot_samples = len(source_main_labels)\n","      train_main_loss_val += loss_M.item()\n","      train_main_acc_val += running_corrects/tot_samples\n","      \n","\n","\n","      # entropy minimization\n","      # setup TARGET DOMAIN STANDARD dataset to feed to the net\n","      target_rgb_images = T[\"rgb\"].to(DEVICE)\n","      target_depth_images = T[\"depth\"].to(DEVICE)\n","      # target labels in this phase can't be used for training\n","      # train on source original images \n","      outputs, out_aux = net.forward(target_rgb_images, target_depth_images, mode=\"main\")\n","      loss_entropy_min = entropy_min_criterion(outputs)\n","      loss_ent_aux = entropy_min_criterion(out_aux)\n","\n","\n","      # PRETEXT TASK \n","      # setup  SOURCE DOMAIN ZOOMED dataset to feed to the net\n","      source_zoom_rgb_images = S_hat[\"rgb\"].to(DEVICE)\n","      source_zoom_depth_images = S_hat[\"depth\"].to(DEVICE)\n","      source_zoom_labels = S_hat[\"label\"].to(DEVICE)\n","      # train on source zoomed \n","      outputs, out_aux = net.forward(source_zoom_rgb_images, source_zoom_depth_images, mode=\"pretext\")\n","      loss_P_1 = criterion(outputs, source_zoom_labels) \n","      loss_src_rot_aux = criterion(out_aux, source_zoom_labels)\n","      # compute stats\n","      _, preds = torch.max(outputs.data, 1)\n","      running_corrects = torch.sum(preds == source_zoom_labels.data).data.item()\n","      tot_samples = len(source_zoom_labels)\n","      train_zoom_source_acc_val += running_corrects/tot_samples\n","      train_zoom_source_loss_val += loss_P_1.item()\n","\n","\n","\n","      #setup TARGET DOMAIN ZOOMED dataset to feed to the net\n","      target_zoom_rgb_images = T_hat[\"rgb\"].to(DEVICE)\n","      target_zoom_depth_images = T_hat[\"depth\"].to(DEVICE)\n","      target_zoom_labels = T_hat[\"label\"].to(DEVICE)\n","      # train on target zoomed\n","      outputs, out_aux = net.forward(target_zoom_rgb_images, target_zoom_depth_images, mode=\"pretext\")\n","      loss_P_2 = criterion(outputs, target_zoom_labels)\n","      loss_trg_rot_aux = criterion(out_aux, target_zoom_labels)\n","      # compute stats\n","      _, preds = torch.max(outputs.data, 1)\n","      running_corrects = torch.sum(preds == target_zoom_labels.data).data.item()\n","      tot_samples = len(target_zoom_labels)\n","      train_zoom_target_acc_val += running_corrects/tot_samples\n","      train_zoom_target_loss_val += loss_P_2.item()\n","\n","\n","      # BACKPROP WITH THE FULL LOSS\n","      loss = loss_M + 0.3*(loss_aux) +\\\n","         (em_weight/tot_samples)*(loss_entropy_min + 0.3*loss_ent_aux) +\\\n","          lambda_*(loss_P_1 + loss_P_2 + 0.3*(loss_src_rot_aux + loss_trg_rot_aux) )\n","\n"," \n","      loss.backward() \n","      # UPDATE GRADIENTS\n","      batch_count += 1\n","      # UPDATE GRADIENTS accumulated --> batch size 8 --> update each 16 elements \n","      if batch_count % 2 == 0:\n","        optimizer.step()\n","      del source_rgb_images , source_depth_images , source_main_labels, target_depth_images, target_rgb_images\n","      del source_zoom_rgb_images, source_zoom_depth_images, source_zoom_labels\n","      del target_zoom_rgb_images, target_zoom_depth_images, target_zoom_labels \n","      n_iters += 1\n","    \n","    train_acc.append(train_main_acc_val/n_iters)\n","    train_loss.append(train_main_loss_val/n_iters)\n","\n","    print(\"EPOCH \", i + 1)\n","    print(\"train main accuracy: \", train_main_acc_val/n_iters)\n","    print(\"train main loss: \", train_main_loss_val/n_iters)\n","    print(\"train zoom source acc: \", train_zoom_source_acc_val/n_iters)\n","    print(\"train zoom source loss: \", train_zoom_source_loss_val/n_iters)\n","    print(\"train zoom target acc: \", train_zoom_target_acc_val/n_iters)\n","    print(\"train zoom target loss: \", train_zoom_target_loss_val/n_iters)\n","\n","\n","    net.eval()\n","    n_iters = 0\n","    tot_samples = 0\n","    validation_corrects = 0\n","    validation_main_loss_val = 0\n","    for source_val_batch in source_validation:\n","      S, _ = format_batch(source_val_batch, pretext_task=\"zoomclf\")\n","     \n","      # MAIN TASK\n","      # setup SOURCE DOMAIN STANDARD dataset to feed to the net\n","      source_rgb_images = S[\"rgb\"].to(DEVICE)\n","      source_depth_images = S[\"depth\"].to(DEVICE)\n","      source_main_labels = S[\"label\"].to(DEVICE)\n","      \n","      outputs = net.forward(source_rgb_images, source_depth_images, mode=\"main\")\n","      loss_M = criterion(outputs, source_main_labels)\n","      \n","      _, preds = torch.max(outputs.data, 1)\n","      validation_corrects += torch.sum(preds == source_main_labels.data).data.item()\n","      tot_samples += len(source_main_labels)\n","      validation_main_loss_val += loss_M.item()\n","      del source_rgb_images , source_depth_images , source_main_labels\n","      n_iters += 1\n","          \n","    validation_acc.append(validation_corrects/tot_samples)\n","    validation_loss.append(validation_main_loss_val/n_iters)\n","    print(\"validation main accuracy: \", validation_corrects/tot_samples)\n","    print(\"validation main loss: \", validation_main_loss_val/n_iters)\n","    \n","\n","    # TEST RESULTS OF THE CURRENT BATCH OF TRAINING\n","    if not light_validation or i == epochs - 1:\n","      net.eval() \n","      n_iters = 0\n","      for target_batch in target: \n","        # Format batch\n","        T, _ = format_batch(target_batch, pretext_task=\"zoomclf\")\n","\n","        # prepare target data\n","        target_rgb_images = T[\"rgb\"].to(DEVICE)\n","        target_depth_images = T[\"depth\"].to(DEVICE)\n","        target_main_labels = T[\"label\"].to(DEVICE)\n","\n","        outputs = net.forward(target_rgb_images, target_depth_images, mode=\"main\")\n","        loss_T = criterion(outputs, target_main_labels)\n","\n","        # compute test stats\n","        _, preds = torch.max(outputs.data, 1)\n","        running_corrects = torch.sum(preds == target_main_labels.data).data.item()\n","        test_main_acc_val += running_corrects/len(target_main_labels)\n","        test_main_loss_val += loss_T.item()\n","        del target_depth_images, target_rgb_images, target_main_labels\n","        n_iters += 1\n","      \n","      test_loss.append(test_main_loss_val/n_iters)\n","      test_acc.append(test_main_acc_val/n_iters)\n","\n","      print(\"test main target accuracy: \", test_main_acc_val/n_iters)\n","      print(\"test main target loss: \", test_main_loss_val/n_iters)\n","\n","    print()\n","\n","    #apply decay policy\n","    if use_fixed_stepsize == False and iter_count % (next_update_epoch) == 0:\n","      for g in optimizer.param_groups:\n","        g['lr'] = lr*curr_gamma\n","      lr = lr*curr_gamma\n","      slow_schedule_count += 1\n","      next_update_epoch = slow_schedule_count**decay_policy\n","    else: # else use fixed step size\n","      scheduler.step()\n","    iter_count += 1\n","  \n","  return net, train_loss, train_acc, validation_loss, validation_acc, test_loss, test_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mK9OhQxJLuoZ","colab_type":"text"},"source":["## ROD and synROD - zoom\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zuh17u3HL5ZF","colab":{}},"source":["tfConfig = TransformConfig(resize_shape=299, centercrop_shape=299)  \n","# config types are imagenet, rgb_mod, depth_mod, rgb_depth_mod                              \n","synrod_param_values, rod_param_values = tfConfig.get_zoom_configuration(config_type=\"imagenet\")    # mod corresponds to the modification of imagenet weights with the computed ones"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Y8soSqM1L5Zd","colab":{}},"source":["synrod_train = SynRODMOD(synrod_path,\n","                split_path=\"/content/synARID_50k-split_sync_train1.txt\",\n","                item_extractor_fn=\"zoomclf\",\n","                item_extractor_param_values= synrod_param_values,\n","                )\n","\n","synrod_validation = SynRODMOD(synrod_path,\n","                split_path=\"/content/synARID_50k-split_sync_test1.txt\",\n","                item_extractor_fn=\"zoomclf\",\n","                item_extractor_param_values= synrod_param_values,\n","                )\n","\n","rod = RODMOD(rod_path,\n","              split_path=\"/content/rod-split_sync.txt\",\n","              item_extractor_fn=\"zoomclf\",\n","              item_extractor_param_values=rod_param_values,\n","              )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wjhW011K103u","colab_type":"text"},"source":["## tuning"]},{"cell_type":"code","metadata":{"id":"zZK3XCEa136C","colab_type":"code","colab":{}},"source":["parameters_dict = { \"lr\" : [0.0003, 0.0001],\n","                    \"batch_size\":[8],\n","                   \"gamma\":[0.10],\n","                   \"epochs\":[10],\n","                   \"weight_decay\":[5e-2],\n","                    \"step_size\": [1, 3],\n","                   \"lambda\": [1.0],\n","                  \"lr_epoch_num_decay_policy\" : [1, 2, 3, None] # 1 == lr reduction after every epoch   used for fast decay\n","                                                          #  2 == lr reduction at \"positive natural number squared\"  epochs[ 1-4-9-16-...] slower decay\n","                                                          #  3 == lr reduction at \"positive natural number cubed\"  epochs[ 1-8-27-64-...]  slowest decay\n","                                                          #  None == lr reduction every \"stepsize number\" of  epochs (step size 3 -> update at epoch [3-6-9-12-...])\n","                   }\n","paramGrid = ParameterGrid(parameters_dict)\n","paramgrid_list = [grid_val for grid_val in paramGrid]\n","\n","\n","log_file = \"variation_tuning.csv\"\n","SAVE_FOLDER = \"/content/drive/My Drive/DL_project/logs/\"\n","if not os.path.exists(SAVE_FOLDER):\n","  os.makedirs(SAVE_FOLDER)\n","SAVE_PATH = SAVE_FOLDER + log_file\n","# Create or overwrite file with heading\n","with open(SAVE_PATH, \"w\") as f:\n","  header = ['lr', 'batch_size', 'epochs', 'weight_decay', 'step_size', 'lambda', \"train_accuracy\", \"train_loss\", \"rod_accuracy\", \"rod_loss\"]\n","  f.write(\", \".join(header) + '\\n')\n","  f.close()\n","\n","# Now open in append mode\n","f = open(SAVE_PATH, \"a\")\n","\n","for grid in paramgrid_list:\n","    print(\"CONFIG:\")\n","    print(grid)\n","\n","  # Train net\n","    net, train_loss, train_acc, validation_loss, validation_acc, test_loss, test_acc = train_test_variation(synrod_train, synrod_validation, rod, grid, light_validation=False)\n","  \n","  # Append on file\n","    config_data = [grid['lr'], grid['batch_size'], grid['epochs'], grid['weight_decay'], grid['step_size'], grid['lambda'],\n","                  train_acc[-1], train_loss[-1], test_acc[-1], test_loss[-1]]\n","    f.write(\", \".join([str(el) for el in config_data]) + '\\n')\n","    f.flush()\n","    model_save_path = os.path.join(SAVE_FOLDER,  \"_\".join([str(el) for el in config_data]) + \".pth\"  )\n","    torch.save(net.state_dict(), model_save_path)\n","    plot_title = \"train and source validation\"\n","    learning_curves(train_acc, train_loss, validation_acc, validation_loss,plot_title , plot_size=(16,6))\n","    plot_title = \"train and target validation\"\n","    learning_curves(train_acc, train_loss, test_acc, test_loss,plot_title , plot_size=(16,6))\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"og02qD_fzFyX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}